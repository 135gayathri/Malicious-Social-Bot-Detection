# Malicious-Social-Bot-Detection
Malicious social bot is a software program that pretends to be a real user in online social networks (OSNs). Moreover, malicious social bots perform several malicious attacks, such as spread social spam content, generate fake identities, manipulate online ratings, and perform phishing attacks. In Twitter, when a participant (user) wants to share a tweet containing URI(s) with the neighboring participants (i.e., followers or following), the participant adapts URL shortened service (i.e., bit.ly) in order to reduce the length of URL (because a tweet is restricted up to 140 characters). Moreover, a malicious social bot may post shortened phishing URLs in the tweet. When a participant clicks on a shortened phishing URL, the participant's request will be redirected to intermediate URLS associated with malicious servers that, in turn, redirect the user to malicious web pages. Then, the legitimate participant is exposed to an attacker. This leads to Twitter network suffering from several vulnerabilities (such as phishing attack).

The malicious behavior of participants is analyzed by considering features extracted from the posted URLs (in the tweets), such as URL redirection, frequency of shared URLs, and spam content in URL, to distinguish between legitimate and malicious tweets. To protect against the malicious social bot attack. Several approaches have been proposed to detect spam in the Twitter network. These approaches are based on tweet- content features, social relationship features, and user profile features. However, the malicious social bots can manipulate profile features, such as hashtag ratio, follower ratio, URL ratio, and the number of retweets. The malicious social bots can also manipulate tweet-content features, such as sentimental words, emoticons, and most frequent words used in the tweets, by manipulating the content of each tweet. The social relationship-based features are highly robust because the malicious social bots cannot easily manipulate the social interactions of users in the Twitter network. However, extracting social relationship-based features consumes a huge amount of time due to the massive volume of social network graph.
The proposed method in this project leverages a Learning Automata-based Malicious Social   Bot   Detection (LA-MSBD) algorithm to identify and classify malicious bots on Twitter. This approach introduces a dual-layer trust computation model that utilizes direct trust and indirect trust metrics to assess user trustworthiness based on URL-sharing behaviors. Direct trust is calculated using Bayesâ€™ theorem, which evaluates individual tweets, while indirect trust is derived from Dempster-Shafer theory, combining multiple interactions to address uncertainties and inconsistencies in tweet patterns. By focusing on URL-based features, the model captures bot-like behaviors effectively, distinguishing them from legitimate user activities. The combination of these trust measures enhances the model's accuracy, precision, recall, and F-measure, making it a robust tool for bot detection. This hybrid trust model, based on evidence aggregation and probabilistic analysis, provides a comprehensive and reliable mechanism to detect social bots in real-time social media environments.
